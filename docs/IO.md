# Cats Effect IOに関して

[メモ]
Future/IOの違い -> 非同期/同期の話 -> そもそもスレッドって何？ -> スレッドにも種類がある -> Javaはどんなスレッド？ -> なぜJavaはネイティブスレッド？
-> Scalaで使ってるFutureは？ -> 普段使ってるExecutionContextって？ -> じゃあIOは何が違う？ -> まずEffectパターンとは? -> 実行遅らせる？実行するときは？
-> IORuntimeって？ -> IOって結局どんなもの？ -> 各スレッドのパフォーマンスは？ -> まとめ

## 目次
- Future/IO違い
- 非同期/同期
- スレッドとは
- スレッドの種類
  - ネイティブスレッド
  - グリーンスレッド
- スレッドプール
  - ワークスティーリング
  - Fork/Join
- Javaのスレッド
- JVMはOSのスレッドを使用
- Futureパターン
  - ExecutionContextとは
- IO
  - Effectパターン
  - IORuntimeとは
- Future/IOのパフォーマンス
- まとめ

## Future/IO違い

[メモ]

|     | Future              | IO           |
|-----|---------------------|--------------|
| 評価  | 逐次                  | 遅延           |
| 実行  | ExecutionContextが必要 | IORuntimeが必要 |
| サイズ | 1M                  | 150byte      |
| 重要視 | 公平性                 | スループットの最適化   |


### Futureの特徴
[メモ]
- 言語の標準ライブラリとして提供されている
  - 利用者が多い
  - 対応しているライブラリが多い
  - 処理をExecutionContextの実行戦略に従って非同期化する
  - 処理を即時実行する
    - Futureは作成と同時に、対応する処理を否応なしに実行してしまいます
    - 作成に副作用を伴います
  - Futureは作成時に実行される処理の結果をメモ化し、再利用された場合も結果が変わらない
  - 作成にExecutionContextを暗黙に要求
    - 使い回すには少し不便

### IOの特徴
[メモ]
- 参照透過
  - 式を評価値で置き換えても挙動に変更がない性質
- 実行するものを作るというよりも、いつか起こす作用の設計図を作るイメージ
- 実行がend-of-the-world
- Fiberと呼ばれるグリーンスレッドを使用
- 遅延評価つきFuture
- 複数のファイバーが同じスレッドを争奪する必要がある場合は、互いに協力して譲り合うことになります。
- ファイバーが降伏する頻度やタイミングは実装に依存します。Cats-Effect では、あなたが降伏するよう指示するまで降伏しないので、公平性とスループットの間で微調整を行うことができます。
- 通常、M対Nのマッピング（M＝ファイバー、N＝スレッド）で、M＞Nとすることが望ましい。
- ヒープ上のオブジェクト

[疑問]
- グリーンスレッドは軽量と言われているが、ネイティブスレッドは1つ1つのスレッドが重いの？
  - コンテキストスイッチは重いらしい
  - ネイティブスレッド1つが1メガだとしたら、IOのグリーンスレッド(Fiber)は150バイト 
  - 単純計算1ネイティブスレッドにつき、IOのグリーンスレッド(Fiber)は約7,000のスレッドを生成できるということ？ 
  - 仮に7,000スレッドを全て使用中の場合、新たにネイティブスレッドを1つ追加してそちらから新規でFiberを生成することも可能？ 
    - これはIOの実装を見てみないとわからない
- グリーンスレッド(ユーザー空間)は、ネイティブスレッド(OS)と別の場所でネイティブスレッドはOSのスレッドを使用グリーンスレッドは、アプリケーション用に確保したメモリを使用
  - アプリケーションを構築する環境(例えばAWSのECSなど)のメモリがMAX100メガだった場合に、ネイティブスレッドでフルを使う場合とネイティブスレッド20メガ、グリーンスレッド80メガだったら後者の方がスレッド生成は多くなる
    - グリーンスレッドの方が良さそうに聞こえるが、ネイティブスレッドのメリットは？I/O？
    - どんなアプリケーションを構築する場合に、ネイティブスレッドよりグリーンスレッドを使う方がよくなる？
      - 昨今のアプリケーションの求められるものは、アクセス過多(通信リクエストを複数同時にさばくこと)にも耐えうる性能？
      - グリーンスレッドだとECSなどのパフォーマンスをあげなくても対応できる？
- スレッド上のファイバーとCPU上のスレッド
  - 違い
    - スレッドはCPU上でプリエンプティブにスケジュールされるが、ファイバーはスレッド上で協調的にスケジュールされる
  - 共通点
    - CPUはブロッキングについて何も知らないので、ただただスレッドをぐるぐる回し続けるだけ
    - ファイバーをブロックしても、その下のスレッドがブロックされるわけではない
      - ファイバーをブロックするということは、単にそのファイバーが他のファイバーにスレッドを譲り渡し、再びスケジュールされるまで待機するということ
      - スレッドはシステム・リソースなので、ブロックしないようにすべきですが、ファイバーに関してはブロックしても問題ない

## 非同期/同期
[メモ]
- 非同期処理は、スレッドプールの必要性に基づいて3つのグループに分けられる。
  - ノンブロッキング非同期処理（HTTPリクエスト、データベースコールなど
  - ブロック型非同期処理（例：ファイルシステムからの読み込み
  - CPU負荷の高い処理（ビットコインの採掘など

- ノンブロッキングの非同期操作
  - 非常に少ない数のスレッド（1つだけかもしれません）で、非常に高い優先順位を持つバウンデッドプール。これらのスレッドは基本的にほとんどの時間アイドル状態で、新しい非同期 IO 通知があるかどうかポーリングしつづけます。これらのスレッドがリクエストの処理に費やす時間は、直接アプリケーションのレイテンシに対応します。したがって、通知を受け取ってアプリケーションの残りの部分に転送すること以外に、このプールで他の作業が行われないことが非常に重要です。
- 非同期操作をブロックする。
  - 非束縛キャッシュ・プール。ブロック操作はスレッドをしばらくの間ブロックする可能性があり、その間に他の I/O リクエストに対応できるようにしたいため、無制限。キャッシュされるのは、あまりに多くのスレッドを作成するとメモリ不足になる可能性があるため、既存のスレッドを再利用することが重要だからです。
- CPUに負荷のかかる操作
  - スレッド数がCPUコア数と等しくなるように固定されたプール。これは非常に簡単です。昔は、スレッド数＝CPUコア数＋1が「黄金律」でしたが、「＋1」は、余分なスレッドを常にI/O用に予約していたことに由来します（上で説明したように、現在はそのために別のプールが用意されています）。

## スレッドとは
[メモ]
- CPU利用の単位
- ある処理を単一のスレッドのみを用いて動作させる環境もしくは手法をシングルスレッドという。対して、複数のスレッドが同時に動作することをマルチスレッドという。
- プログラム（概ねプロセス）の開始時にはメインとなるスレッドが動作する。必要に応じてその他の処理をするスレッドを作り、実行させる事も出来る。

## ネイティブスレッド
## グリーンスレッド

[メモ]
- OSではなく仮想マシンやランタイムライブラリによってスケジュールされるスレッド。グリーンスレッドは、OSの機能によらずにマルチスレッド環境をエミュレートする。
- OSではなくアプリケーションレベルで実装されるスレッド
- カーネルのスレッドに関するサポートが受けられない環境上で、マルチスレッドを実行することができます。
- 注意：ここでの仮想マシンはVMwareやKVM等のOSを実行するために仮想マシンではなく、JVMなどの言語処理系の仮想マシンになります。
- シングルプロセッサ上では、カーネルスレッドとグリーンスレッドのどちらがよいパフォーマンスを発揮するかは一般的には明らかではありません。
- ネイティブスレッドは I/O や コンテキストスイッチの処理に関して、大きく上回る
- OSがスタックを作成するのではなく、ヒープから割り当てられます。これにより、並列スレッドが1桁以上増加する可能性があります
- 仮想スレッドのライフサイクルにOSが関与しなくなることで、スケーラビリティのボトルネックが解消されます
- ランタイムライブラリや仮想マシンによってスケジューリングされ、カーネル空間の代わりにユーザー空間で管理され、通常プリエンプティブスケジューリングの代わりに協調的スケジューリングを使用する軽量スレッド

### カーネル空間
[メモ]
- 階層型に設計されたオペレーティングシステム (OS) の中核となる部分
- アプリケーションとハードウェアレベルでの実際のデータ処理との間の架け橋
- システムのリソースを管理し、ハードウェアとソフトウェアコンポーネントのやりとりを管理
- オペレーティングシステムの基本コンポーネントとして、カーネルはメモリ、CPU、入出力を中心としたハードウェアを抽象化し、ハードウェアとソフトウェアがやり取りできるようにする
- ユーザープログラムのための機能として、プロセスの抽象化、プロセス間通信、システムコールなどを提供する
- オペレーティングシステムのカーネルが存在する仮想メモリ領域である

### ユーザー空間 (アドレス空間)
[メモ]
- メモリアドレスが意味を成すコンテキストを定義したもの
- 一連のメモリアドレスによってアクセス可能なメモリ空間を意味する
- ユーザー空間に構築されているため、グリーンスレッドはネイティブスレッドより軽量
- スレッドの起床と同期化について、ネイティブスレッドの性能を上回る

アドレス空間の例：
*主記憶装置（物理メモリ）
*仮想メモリ
*I/O ポート空間
*IPアドレス

Macのアクティビティモニタで、使用しているスレッド、プロセスの数その割合(OS, ユーザー)を確認できる

![](Thread.png)

## スレッドプール
### ワークスティーリング
### Fork/Join

## Javaのスレッド

## JVMはOSのスレッドを使用
[メモ]
- 最初期のJVM実装では、実際にはプラットフォーム・スレッドを1つしか使わなかったので、この仕組みはグリーン・スレッドと呼ばれていました。
- Java 1.2とJava 1.3の時代（SunのSolaris OSの少し前）あたりで消滅しました。その代わりとして、主流のOSで実行される最近のバージョンのJavaでは、1つのJavaスレッドが厳密に1つのOSスレッドと対応するというルールが実装されています。
- Thread.start()を使うと、スレッドを作成するシステム・コール（Linuxのclone()など）が呼び出され、新しいOSスレッドが実際に作成されます。
- Java 1.0のときのマルチスレッドの主な要求は、ロジック進行によってGUIが止まらないようにする、たとえば処理中にプログレスバーがちゃんと表示できるようにするものだったのだけど、いまのマルチスレッドの主な要求は通信リクエストを複数同時にさばくことに変化してる。
- OpenJDKのProject Loomが仮想スレッドを追加実装しようとしている
- JVMのスレッドは、OSのネイティブスレッドに1対1でマッピングされる
- CPUがあるスレッドの実行を停止し、別のスレッドの実行を開始すると、OSは以前のタスクの状態を保存し、現在のタスクのために状態を復元する必要があります。このコンテキストスイッチにはコストがかかり、スループットが犠牲になる
- スループットをある程度犠牲にして、公平性を確保することで、すべてのタスクがCPU時間のシェアを得ることを確実にし、どのタスクも長く待たされることがないようできる

## Futureパターン

[メモ]
- scala.concurrent.Futureは、scala.concurrent.ExecutionContextを介して複数のスレッドで作業をスケジューリングすることにより並列処理をサポートしている。
- 内部的にはJavaのRunnableに変換される
  - このRunnableをExecutionContextが良い感じにスレッドに割り当ててくれる
  - OSのスケジューラーにより均等に割り当てられ、実行されていく
- Map / FlatMapの呼び出しごとにExecutionContextを渡すので、Futureの計算はそれぞれ別のスレッドで実行される
- Futureでは、2つの同時実行計算を定義して、同じスレッドを協調的に再利用することはできない。

## IO
### Effectパターン
### IORuntimeとは
#### Schedulers
- IOプログラムとファイバーは、最終的にJVMスレッドで実行され、それ自体がカーネルスレッドに直接マッピングされ、最終的に（スケジュールされた場合）プロセッサーにマッピングされます
- IOは3つの独立したスレッドプールを利用してプログラムを評価している
  - ハードウェアプロセッサと同数のスレッドからなる計算用ワークスティーリングプール（最小：2個）
  - 高精度でスリープをディスパッチする最大優先度のスレッド1つからなるシングルスレッド・スケジュール・ディスパッチャ。
  - デフォルトで 0 Threads に設定され、ブロック操作の需要に応えるために必要に応じて（キャッシュとダウンサイジングで）割り当てられる無制限のブロッキングプール
- ワークスティーリングプールは、Tokio Rust フレームワークから派生した非常に高性能な実装
- 

## Future/IOのパフォーマンス
## まとめ

## 参考文献
- [デザインパターン紹介](https://www.hyuki.com/dp/dpinfo.html#Future)
- [作って学ぶ、cats.effect.IO モナドのしくみ](https://blog-dry.com/entry/2020/01/04/140139#f-822e1275)
- [cats.effectのIOモナドとcontextshiftを丁寧に理解する](https://sakataharumi.hatenablog.jp/entry/2020/08/30/230025)
- [Cats Effect - How it works technically?](https://www.reddit.com/r/scala/comments/s23dve/cats_effect_how_it_works_technically/)
- [なぜ Go では何百万もの Goroutine を作れるのに Java は数千のスレッドしか作れないのか?](https://mahata.gitlab.io/post/2018-10-15-goroutines-vs-java-threads/)
- [並列処理の用語](https://alexei-karamazov.hatenablog.com/entry/2014/04/20/105644)
- [マルチスレッドモデル](https://docs.oracle.com/cd/E19620-01/805-5818/6j5g78lkj/index.html)
- [JavaのProject Loomと仮想スレッドの内部](https://blogs.oracle.com/oracle4engineer/post/going-inside-javas-project-loom-and-virtual-threads-ja)
- [Java’s Thread Model and Golang Goroutine](https://medium.com/@genchilu/javas-thread-model-and-golang-goroutine-f1325ca2df0c)
- [[ 図解 ] 初心者向けユーザー空間とカーネル空間,システムコール,MMU/メモリ保護,の仕組み](https://milestone-of-se.nesuke.com/sv-basic/architecture/user-space-kernel-space/)
- [[ 図解 ] 仮想記憶(仮想メモリ)の本質や仕組み、メリット　〜スワップ、MMU、ページングテーブルについて〜](https://milestone-of-se.nesuke.com/sv-basic/architecture/virtual-memory-and-swap/)
- [Concurrency In Scala with Cats-Effect](https://github.com/slouc/concurrency-in-scala-with-ce)
- [The fork/join framework in Java 7](http://www.h-online.com/developer/features/The-fork-join-framework-in-Java-7-1762357.html)
- [Cats Effect 3 - Introduction to Fibers](https://blog.rockthejvm.com/cats-effect-fibers/)
- [Cats Effect 3 - Racing IOs](https://blog.rockthejvm.com/cats-effect-racing-fibers/)
- [さあ、並列プログラミングをはじめよう](https://qiita.com/koduki/items/086d42b5a3c74ed8b59e#akka)
- [Work stealing](https://en.wikipedia.org/wiki/Work_stealing)
- [[非同期処理] [雑記] スレッド プールとタスク](https://ufcpp.net/study/csharp/misc_task.html#thread_pool4)
